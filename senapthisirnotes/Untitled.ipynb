{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3b7fb6-7864-455d-a24a-d29e3186cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e35630f-677c-44e1-9272-d2ad5fa57528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also create your own words\n",
    "AI = '''Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\n",
    "humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\n",
    "problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\n",
    "It is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\n",
    "AI could solve major challenges and crisis situations.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858517fe-fefe-44e3-9c29-645fe53ee35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd8c7033-58e7-4eea-9081-d8a8f07f2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520fb8e5-3f07-4674-a5f6-39ee373eade5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_tokens=word_tokenize(AI)\n",
    "AI_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4601248-00f9-4edc-a32a-571a22ba0768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef424e5f-b701-4306-9ba0-e22e2b6e00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e5922a-61fa-4633-b918-bdb528bd0049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines.',\n",
       " 'This is in contrast to the natural intelligence of\\nhumans and animals.',\n",
       " 'With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving.',\n",
       " 'Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.',\n",
       " 'It is probably the fastest-growing development in the World of technology and innovation.',\n",
       " 'Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_sent=sent_tokenize(AI)\n",
    "AI_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a203c77-b4c2-4097-b7e3-097fb55f77dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b4a234-832e-42b6-8324-7c67d4a30670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "AI_blank=blankline_tokenize(AI)\n",
    "AI_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e03478e3-420b-45a6-ae08-c9cd34113268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80f27b3c-c062-40cb-937c-6700e7132eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence,',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning,',\n",
       " 'planning,',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving.',\n",
       " 'Most',\n",
       " 'noteworthy,',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation.',\n",
       " 'Furthermore,',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "wt=WhitespaceTokenizer().tokenize(AI)\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9922d52f-333c-4a2a-b0f3-e857790c7247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f0f8767-ac93-4f71-a61c-f73966454de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#types of tokens\n",
    "from nltk.util import bigrams,trigrams,ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c16f9cea-eb79-48df-98b5-6ba64cfbfad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['welcome', 'to', '2025', 'placement', 'batch', 'naresh', 'i', 'technology']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string='welcome to 2025 placement batch naresh i technology'\n",
    "quotes_tokens=nltk.word_tokenize(string)\n",
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c16df436-d9fe-41da-b218-404adcb652d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('welcome', 'to'),\n",
       " ('to', '2025'),\n",
       " ('2025', 'placement'),\n",
       " ('placement', 'batch'),\n",
       " ('batch', 'naresh'),\n",
       " ('naresh', 'i'),\n",
       " ('i', 'technology')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_bigrams=list(nltk.bigrams(quotes_tokens))\n",
    "quotes_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c30343b-27e6-4b26-9730-381cd74ee2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('welcome', 'to', '2025'),\n",
       " ('to', '2025', 'placement'),\n",
       " ('2025', 'placement', 'batch'),\n",
       " ('placement', 'batch', 'naresh'),\n",
       " ('batch', 'naresh', 'i'),\n",
       " ('naresh', 'i', 'technology')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_trygrams=list(nltk.trigrams(quotes_tokens))\n",
    "quotes_trygrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4862c032-6d19-4183-991e-ad420c859d20",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ngrams() missing 1 required positional argument: 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m n_grams\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(nltk\u001b[38;5;241m.\u001b[39mngrams(quotes_tokens)) \u001b[38;5;66;03m#because take one variable mention how many words the every line\u001b[39;00m\n\u001b[0;32m      2\u001b[0m n_grams\n",
      "\u001b[1;31mTypeError\u001b[0m: ngrams() missing 1 required positional argument: 'n'"
     ]
    }
   ],
   "source": [
    "n_grams=list(nltk.ngrams(quotes_tokens)) #because take one variable mention how many words the every line\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21bc0b-4dc2-486b-8121-f0f22d0633e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams=list(nltk.ngrams(quotes_tokens,4))\n",
    "n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d72455f-bdbc-4203-8a43-c90dec14ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b981de5-9429-49fa-8f6e-52d2aedab0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affect'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('affection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0077b5eb-9645-4f90-9d78-a34c3faf88f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('playing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbae3953-9442-4462-a88d-eba10b9a771b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('played')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebfaa934-a092-4969-a5da-98cc55834a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maximum'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeaa3a7b-b16c-4cc5-8e47-39427ac22c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n",
      "loving:love\n",
      "maximum:maximum\n"
     ]
    }
   ],
   "source": [
    "word_to_stem=['give','giving','given','gave','loving','maximum']\n",
    "for words in word_to_stem:\n",
    "    print(words+':'+pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aad8ba98-0c8f-43be-9181-b780cc6ea4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:giv\n",
      "giving:giv\n",
      "given:giv\n",
      "gave:gav\n",
      "loving:lov\n",
      "maximum:maxim\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lst=LancasterStemmer()\n",
    "word_to_stem=['give','giving','given','gave','loving','maximum']\n",
    "for words in word_to_stem:\n",
    "    print(words+':'+lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87b33c99-9f64-4b92-a15a-03d2854ef78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:giving\n",
      "given:given\n",
      "gave:gave\n",
      "loving:loving\n",
      "maximum:maximum\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem=WordNetLemmatizer()\n",
    "word_to_stem=['give','giving','given','gave','loving','maximum']\n",
    "for words in word_to_stem:\n",
    "    print(words+':'+word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7001b8d-e218-4cff-8ecd-c95bffa3cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a573ea55-818c-4555-b961-58dc12314d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a115f7a-1451-4ccc-99f6-cc7b1527ae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9164ccd4-2364-4430-961b-88470b342789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aber',\n",
       " 'alle',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderem',\n",
       " 'anderen',\n",
       " 'anderer',\n",
       " 'anderes',\n",
       " 'anderm',\n",
       " 'andern',\n",
       " 'anderr',\n",
       " 'anders',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dann',\n",
       " 'der',\n",
       " 'den',\n",
       " 'des',\n",
       " 'dem',\n",
       " 'die',\n",
       " 'das',\n",
       " 'dass',\n",
       " 'daß',\n",
       " 'derselbe',\n",
       " 'derselben',\n",
       " 'denselben',\n",
       " 'desselben',\n",
       " 'demselben',\n",
       " 'dieselbe',\n",
       " 'dieselben',\n",
       " 'dasselbe',\n",
       " 'dazu',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'deinem',\n",
       " 'deinen',\n",
       " 'deiner',\n",
       " 'deines',\n",
       " 'denn',\n",
       " 'derer',\n",
       " 'dessen',\n",
       " 'dich',\n",
       " 'dir',\n",
       " 'du',\n",
       " 'dies',\n",
       " 'diese',\n",
       " 'diesem',\n",
       " 'diesen',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'einig',\n",
       " 'einige',\n",
       " 'einigem',\n",
       " 'einigen',\n",
       " 'einiger',\n",
       " 'einiges',\n",
       " 'einmal',\n",
       " 'er',\n",
       " 'ihn',\n",
       " 'ihm',\n",
       " 'es',\n",
       " 'etwas',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'eurem',\n",
       " 'euren',\n",
       " 'eurer',\n",
       " 'eures',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'gewesen',\n",
       " 'hab',\n",
       " 'habe',\n",
       " 'haben',\n",
       " 'hat',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hier',\n",
       " 'hin',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'mich',\n",
       " 'mir',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'ihrem',\n",
       " 'ihren',\n",
       " 'ihrer',\n",
       " 'ihres',\n",
       " 'euch',\n",
       " 'im',\n",
       " 'in',\n",
       " 'indem',\n",
       " 'ins',\n",
       " 'ist',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jene',\n",
       " 'jenem',\n",
       " 'jenen',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'keinem',\n",
       " 'keinen',\n",
       " 'keiner',\n",
       " 'keines',\n",
       " 'können',\n",
       " 'könnte',\n",
       " 'machen',\n",
       " 'man',\n",
       " 'manche',\n",
       " 'manchem',\n",
       " 'manchen',\n",
       " 'mancher',\n",
       " 'manches',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'meinem',\n",
       " 'meinen',\n",
       " 'meiner',\n",
       " 'meines',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'musste',\n",
       " 'nach',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'noch',\n",
       " 'nun',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'ohne',\n",
       " 'sehr',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'seinem',\n",
       " 'seinen',\n",
       " 'seiner',\n",
       " 'seines',\n",
       " 'selbst',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'ihnen',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'solche',\n",
       " 'solchem',\n",
       " 'solchen',\n",
       " 'solcher',\n",
       " 'solches',\n",
       " 'soll',\n",
       " 'sollte',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'über',\n",
       " 'um',\n",
       " 'und',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'unserem',\n",
       " 'unseren',\n",
       " 'unser',\n",
       " 'unseres',\n",
       " 'unter',\n",
       " 'viel',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'während',\n",
       " 'war',\n",
       " 'waren',\n",
       " 'warst',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'weil',\n",
       " 'weiter',\n",
       " 'welche',\n",
       " 'welchem',\n",
       " 'welchen',\n",
       " 'welcher',\n",
       " 'welches',\n",
       " 'wenn',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'wollen',\n",
       " 'wollte',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'zwar',\n",
       " 'zwischen']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00fbde7b-973f-45be-9317-9ca1d32767e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29e6d3ba-0a70-4ef3-8d75-5d2977cab3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc6a448b-4ca1-4266-bbb9-4f610f847af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('chinese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e84882da-43da-4b05-987d-b689d041adfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('tamil'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64cb12d7-586c-425f-8acd-f6a89603b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords.words('hindi') # not availble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86ab10cb-23c9-4f4b-80e2-f93999f8fb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sam', 'is', 'a', 'natural', 'when', 'it', 'comes', 'to', 'drawing']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent='sam is a natural when it comes to drawing'\n",
    "sent_tokens=word_tokenize(sent)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17090985-9cc8-4c83-89e3-8c3f66c09d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sam', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('drawing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45e683ba-5644-4bfb-aa1c-bfc3d194d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f83a578f-8420-4bde-a1a7-885d52116cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_sent='The US president stays in the WHITEHOUSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e48603b6-8745-460d-9c1b-762f4cc4e19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'US', 'president', 'stays', 'in', 'the', 'WHITEHOUSE']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NE_tokens=word_tokenize(NE_sent)\n",
    "NE_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82e9eff9-1ae1-4e76-b1d6-94525d6f077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('US', 'NNP'),\n",
       " ('president', 'NN'),\n",
       " ('stays', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('WHITEHOUSE', 'NNP')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NE_tags=nltk.pos_tag(NE_tokens)\n",
    "NE_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0659fb9c-c378-491c-9e55-9b8c00fbed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (GSP US/NNP)\n",
      "  president/NN\n",
      "  stays/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION WHITEHOUSE/NNP))\n"
     ]
    }
   ],
   "source": [
    "#nlu techniques\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "NE_NER=ne_chunk(NE_tags)\n",
    "print(NE_NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e299b9c-2c7f-4c7a-a745-b4242fe51daf",
   "metadata": {},
   "source": [
    "## work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "592ab4ac-f5ac-46d3-a86e-e251d3e31c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On',\n",
       " 'a',\n",
       " '$',\n",
       " '50,000',\n",
       " 'mortgage',\n",
       " 'of',\n",
       " '30',\n",
       " 'years',\n",
       " 'at',\n",
       " '8',\n",
       " 'percent',\n",
       " ',',\n",
       " 'the',\n",
       " 'monthly',\n",
       " 'payment',\n",
       " 'would',\n",
       " 'be',\n",
       " '$',\n",
       " '366.88',\n",
       " '.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1=\"On a $50,000 mortgage of 30 years at 8 percent, the monthly payment would be $366.88.\"\n",
    "word_tokenize(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d6383cf-6c79-4dc1-922e-fab9c9ea675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'We',\n",
       " 'beat',\n",
       " 'some',\n",
       " 'pretty',\n",
       " 'good',\n",
       " 'teams',\n",
       " 'to',\n",
       " 'get',\n",
       " 'here',\n",
       " ',',\n",
       " \"''\",\n",
       " 'Slocum',\n",
       " 'said',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = \"\\\"We beat some pretty good teams to get here,\\\" Slocum said.\"\n",
    "word_tokenize(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bbe3f34-dbef-4c8d-bd16-05f951918017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Well',\n",
       " ',',\n",
       " 'we',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'this',\n",
       " 'predictable',\n",
       " ',',\n",
       " 'cliche-ridden',\n",
       " ',',\n",
       " '``',\n",
       " 'Touched',\n",
       " 'by',\n",
       " 'an',\n",
       " 'Angel',\n",
       " \"''\",\n",
       " '(',\n",
       " 'a',\n",
       " 'show',\n",
       " 'creator',\n",
       " 'John',\n",
       " 'Masius',\n",
       " 'worked',\n",
       " 'on',\n",
       " ')',\n",
       " 'wanna-be',\n",
       " 'if',\n",
       " 'she',\n",
       " 'did',\n",
       " \"n't\",\n",
       " '.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = \"Well, we couldn't have this predictable, cliche-ridden, \\\"Touched by an Angel\\\" (a show creator John Masius worked on) wanna-be if she didn't.\"\n",
    "word_tokenize(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6a21494-c2c5-42c6-aefb-51b7a0d9aacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'can', 'not', 'can', 'not', 'work', 'under', 'these', 'conditions', '!']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = \"I cannot cannot work under these conditions!\"\n",
    "word_tokenize(s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34826e93-507f-426b-93e3-3fc63abeb2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'company', 'spent', '$', '30,000,000', 'last', 'year', '.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s5=\"The company spent $30,000,000 last year.\"\n",
    "word_tokenize(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63a8b968-4982-4a51-abaf-95b55383bbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'company',\n",
       " 'spent',\n",
       " '40.75',\n",
       " '%',\n",
       " 'of',\n",
       " 'its',\n",
       " 'income',\n",
       " 'last',\n",
       " 'year',\n",
       " '.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = \"The company spent 40.75% of its income last year.\"\n",
    "word_tokenize(s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b66a7b23-20da-4a55-ac41-b5bdf1f35a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He', 'arrived', 'at', '3:00', 'pm', '.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s7 = \"He arrived at 3:00 pm.\"\n",
    "word_tokenize(s7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24d607eb-a342-4a52-8c2a-aedacad45e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'bought',\n",
       " 'these',\n",
       " 'items',\n",
       " ':',\n",
       " 'books',\n",
       " ',',\n",
       " 'pencils',\n",
       " ',',\n",
       " 'and',\n",
       " 'pens',\n",
       " '.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s8 = \"I bought these items: books, pencils, and pens.\"\n",
    "word_tokenize(s8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96d1b546-e8c3-42bf-8439-193579308a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Though',\n",
       " 'there',\n",
       " 'were',\n",
       " '150',\n",
       " ',',\n",
       " '100',\n",
       " 'of',\n",
       " 'them',\n",
       " 'were',\n",
       " 'old',\n",
       " '.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s9 = \"Though there were 150, 100 of them were old.\"\n",
    "word_tokenize(s9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2623ba3b-154d-492e-98ee-beadec1bb6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There', 'were', '300,000', ',', 'but', 'that', 'was', \"n't\", 'enough', '.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s10 = \"There were 300,000, but that wasn't enough.\"\n",
    "word_tokenize(s10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a5ea22a-c0a2-4ab8-95cd-b09577593547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', \"'s\", 'more', \"'n\", 'enough', '.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s11 = \"It's more'n enough.\"\n",
    "word_tokenize(s11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c09a0c55-6a92-41a2-b901-e468c69cd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/howto/tokenize.html\n",
    "#check above link then understood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac987b-f13e-4110-9913-36afb897a57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747662c4-f1e0-45bd-9b43-4733243de7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60b3d6-1740-426e-b731-9ca1f1ecdbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96693867-577b-4027-93ac-f1fbf1a47059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e9873-2a3b-48f8-abc3-e17bde6ff171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa7077-6701-44a7-9a4a-cabc9902605d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e96167-68b8-436c-8930-8132e930b8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bff5b9-52de-4735-af54-fa091fdf5d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
